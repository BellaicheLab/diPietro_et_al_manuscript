{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "#To run the prediction on the CPU, else comment out this line touse the GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sys.path.append('../Terminator/')\n",
    "import glob\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "from stardist import random_label_cmap, _draw_polygons,dist_to_coord\n",
    "from stardist.models import StarDist2D\n",
    "from TerminatorUtils.helpers import normalizeFloat, OtsuThreshold2D, save_8bit_tiff_imagej_compatible,Integer_to_border,SeedStarDistWatershed\n",
    "from TerminatorUtils.helpers import Prob_to_Binary\n",
    "from TerminatorUtils.helpers import save_tiff_imagej_compatible\n",
    "from csbdeep.models import Config, CARE\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/Users/aimachine/Documents/YohannsTest/'\n",
    "basedirStarResults = '/Users/aimachine/Documents/YohannsTest/Results/'\n",
    "StardistModelName = 'DrosophilaSegmentationStardist'\n",
    "UnetModelName = 'DrosophilaSegmentationUNet'\n",
    "Model_Dir = '/Users/aimachine/Documents/YohannsTest/Model/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aimachine/miniconda3/envs/tensorflowEnv36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/aimachine/miniconda3/envs/tensorflowEnv36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.478882, nms_thresh=0.3.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "WARNING:tensorflow:From /Users/aimachine/miniconda3/envs/tensorflowEnv36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Total number of seeds found: 3285\n",
      "Starting flooding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Terminator/TerminatorUtils/helpers.py:174: UserWarning: Converting data type from 'int32' to ImageJ-compatible 'int16'.\n",
      "  warnings.warn(\"Converting data type from '%s' to ImageJ-compatible '%s'.\" % (t, np.dtype(t_new)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of seeds found: 3337\n",
      "Starting flooding\n",
      "Total number of seeds found: 1757\n",
      "Starting flooding\n",
      "Total number of seeds found: 2988\n",
      "Starting flooding\n",
      "Total number of seeds found: 2975\n",
      "Starting flooding\n",
      "Total number of seeds found: 2981\n",
      "Starting flooding\n",
      "Total number of seeds found: 3037\n",
      "Starting flooding\n",
      "Total number of seeds found: 3218\n",
      "Starting flooding\n",
      "Total number of seeds found: 3195\n",
      "Starting flooding\n",
      "Total number of seeds found: 3078\n",
      "Starting flooding\n",
      "Total number of seeds found: 3133\n",
      "Starting flooding\n"
     ]
    }
   ],
   "source": [
    "model = StarDist2D(config = None, name = StardistModelName, basedir = Model_Dir)\n",
    "UnetModel = CARE(config = None, name = UnetModelName, basedir = Model_Dir)\n",
    "\n",
    "Raw_path = os.path.join(basedir, '*tif')\n",
    "Path(basedirStarResults).mkdir(exist_ok = True)\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "axes = 'YX'\n",
    "filesRaw = glob.glob(Raw_path)\n",
    "filesRaw.sort\n",
    "for fname in filesRaw:\n",
    "        x = imread(fname)\n",
    "        \n",
    "        Name = os.path.basename(os.path.splitext(fname)[0])\n",
    "        x = normalizeFloat(x,1,99.8, axis = axis_norm)\n",
    "        \n",
    "        \n",
    "        #Stardist, label image, details, probability map, distance map\n",
    "        segmentationImage, details = model.predict_instances(x)\n",
    "        prob, dist = model.predict(x)\n",
    "        grid = model.config.grid\n",
    "        prob = cv2.resize(prob, dsize=(prob.shape[0] * grid[0], prob.shape[1] * grid[1]))\n",
    "        \n",
    "        Binary = Prob_to_Binary(prob)\n",
    "        #Seeds from Stardist, segmentation on \n",
    "        Watershed, markers = SeedStarDistWatershed(prob,details['points'],model.config.grid )\n",
    "        \n",
    "        #Convert Integer image to binary\n",
    "        Binary_Watershed = Integer_to_border(Watershed)\n",
    "        #Binary_StarDist = Integer_to_border(segmentationImage)\n",
    "       \n",
    "        #Save different method segmentations\n",
    "        #save_8bit_tiff_imagej_compatible((basedirStarResults+ 'Markers' + Name ) , markers, axes)\n",
    "        #save_tiff_imagej_compatible((basedirStarResults+ 'Probability' + Name ) , prob, axes)\n",
    "        save_tiff_imagej_compatible((basedirStarResults+ 'Watershed' + Name  ) , Watershed, axes)\n",
    "        \n",
    "        save_8bit_tiff_imagej_compatible((basedirStarResults+ 'Binary_Watershed' + Name ) , Binary_Watershed, axes)\n",
    "        save_8bit_tiff_imagej_compatible((basedirStarResults+ 'Binary' + Name ) , Binary, axes)\n",
    "        #save_8bit_tiff_imagej_compatible((basedirStarResults+ 'Binary_Stardist' + Name   ) , Binary_StarDist, axes)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowEnv36]",
   "language": "python",
   "name": "conda-env-tensorflowEnv36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
